# 关于频域学习

之前在做某一个项目时，想把模型的计算量降低、参数量减少，还想做得“花哨”一点。加之现在CV方向的深度学习相关的研究大多都是基于RGB色域（或者说是空间域、空域）进行的，所以突发奇想能不能把这个空域变换到频域上去呢？毕竟从人眼的角度出发，人眼总是对低频的信息更为敏感，而对高频的信息（比如肉眼不可见的噪声）不是那么敏感。然后我去找了一下频域学习在目标检测、图像分割这些方面的应用，发现目前发表的工作不是很多，而且不少的工作都是阿里达摩院完成的。以下是我对频域学习现有工作的一些总结和思考。（截止2021年3月23日）



## 一、引出问题

* 一般情况下，大家对CNN卷积神经网络提取特征的方式的共识都是：最开始提取**low-level**的特征，例如边缘轮廓、纹理等等，然后随着卷积层的加深，网络开始提取**high-level**的抽象特征。实际上这一过程，可以说是CNN网络在隐式对频域进行建模。结合随着CNN的层数逐渐加深，深层特征层上某一点的特征对应的感受野也不断扩大，CNN的这些行为和人类观察事物的过程相当类似。**但是有时候，CNN有时候表现出的行为却让人难以直观解释**。例如下图中，输入一张普通“熊猫”的图片，其预测置信度为57.7%，如果在这张熊猫图片上添加一个**不可察觉的噪声层**，会导致卷积神经网络将熊猫误识别为长臂猿，而且置信度高达99.3%。

  <div align="center">
  <img src="https://markdow-picbed.oss-cn-beijing.aliyuncs.com/img/image-20210305172739085.png" width=700>   
  </div>

* 这些情况通常被称为“对抗样本”（adversarial examples），不经意就改变AI模型的行为。对抗机器学习是当前人工智能体系的最大挑战之一。对抗样本可能会导致机器学习模型的意外失败，或使模型容易受到网络攻击。



## 二、发展历程



### 1.1 基于DCT图像数据的CNN应用研究





### 1.2



### 三、



## 四、总结思考





## 参考资料

### (1) 博客文章

* [1] 频域（DCT,小波变换）与CNN结合 | [[知乎 - 简单控]](https://zhuanlan.zhihu.com/p/342991714)
* [2] CNN — 我不是你想的那样 | [[知乎 - 深度眸]](https://zhuanlan.zhihu.com/p/315601295)
* [3] 也谈阿里达摩院的频域学习论文 | [[知乎 - mileistone]](https://zhuanlan.zhihu.com/p/115584408)
* [4] 即插即用：把仿生模块和CNN拼接，对抗攻击鲁棒性显著提高！| [[腾讯云社区]](https://cloud.tencent.com/developer/article/1762810)

### (2) 相关论文

* [1] Ulicny, Matej, and Rozenn Dahyot. "**On using cnn with dct based image data.**" *Proceedings of the 19th Irish Machine Vision and Image Processing conference IMVIP*. Vol. 2. 2017.
* [2] Gueguen, Lionel, et al. "**Faster neural networks straight from jpeg.**" *Advances in Neural Information Processing Systems* 31 (2018): 3933-3944.
* [4] Rajesh, B. et al. “**DCT-CompCNN: A Novel Image Classification Network Using JPEG Compressed DCT Coefficients.**” *2019 IEEE Conference on Information and Communication Technology* (2019): 1-6.
* [5] Wang, Haohan, et al. "**High-frequency component helps explain the generalization of convolutional neural networks.**" *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*. 2020. | [[阿里达摩院]](https://arxiv.org/abs/1905.13545)[[Github]](https://github.com/HaohanWang/HFC)
* [6] Xu, Kai, et al. "**Learning in the frequency domain.**" *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*. 2020. | [[阿里达摩院]](https://arxiv.org/pdf/2002.12416.pdf)[[Github]](https://github.com/calmevtime/DCTNet)
* [7] Qin, Zequn, et al. "**FcaNet: Frequency Channel Attention Networks.**" *arXiv preprint arXiv:2012.11879* (2020). | [[浙大 - 李玺团队]](https://arxiv.org/abs/2012.11879)[[Github]](https://github.com/dcdcvgroup/FcaNet)

* [8] Shen, Xing, et al. "**DCT-Mask: Discrete Cosine Transform Mask Representation for Instance Segmentation.**" *arXiv preprint arXiv:2011.09876* (2020). | [[阿里达摩院]](https://arxiv.org/pdf/2011.09876.pdf)

  

